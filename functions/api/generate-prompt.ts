// Simplified generate-prompt.ts - same pattern as auth endpoints

import { GoogleGenAI } from "@google/genai";
import type { Language, Domain, OutputLength, PromptType } from '../../types';
import { translations as appTranslations } from '../../constants';

// JWT verification function (same as prompts.ts)
async function verifyJWT(token: string, secret: string): Promise<any> {
  try {
    const [headerB64, payloadB64, signatureB64] = token.split('.');
    if (!headerB64 || !payloadB64 || !signatureB64) {
      throw new Error('Invalid token format');
    }
    
    // Verify signature
    const encoder = new TextEncoder();
    const message = `${headerB64}.${payloadB64}`;
    const key = await crypto.subtle.importKey(
      'raw',
      encoder.encode(secret),
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['verify']
    );
    
    const signature = Uint8Array.from(atob(signatureB64.replace(/-/g, '+').replace(/_/g, '/')), c => c.charCodeAt(0));
    const isValid = await crypto.subtle.verify('HMAC', key, signature, encoder.encode(message));
    
    if (!isValid) {
      throw new Error('Invalid signature');
    }
    
    // Parse payload
    const payload = JSON.parse(atob(payloadB64.replace(/-/g, '+').replace(/_/g, '/')));
    
    // Check expiration
    if (payload.exp < Math.floor(Date.now() / 1000)) {
      throw new Error('Token expired');
    }
    
    return payload;
  } catch (error) {
    throw new Error('Token verification failed');
  }
}

interface GeneratePromptParams {
  rawRequest: string;
  promptType: PromptType;
  domain: Domain;
  language: Language;
  outputLength: OutputLength;
  expertRole: string;
  mission: string;
  constraints: string;
}

// Enhanced metaPromptTranslations with detailed methodology for both approaches
const metaPromptTranslations = {
  en: {
    systemInstructionBase: "You are an expert prompt engineer. Generate a complete, executable prompt following the exact format: <System>, <User>, <Example>. The final prompt must be in {TARGET_LANGUAGE} and ready for immediate use by an AI. Include detailed methodology in the User section and compelling examples. Output ONLY the prompt text - no meta-commentary or explanations outside the prompt structure.",
    
    userQueryHeader: "Please generate a structured prompt. Here are the details:",
    rawRequestLabel: "User's Goal / Raw Request:",
    promptTypeLabel: "Chosen Prompt Structure Type:",
    domainLabel: "Domain:",
    outputLengthLabel: "Desired Output Length for the AI using the generated prompt:",
    expertRoleLabel: "Expert Role for the AI using the generated prompt:",
    missionLabel: "Main Mission for the AI using the generated prompt:",
    constraintsLabel: "Constraints for the AI using the generated prompt (one per line):",
    noneSpecified: "None specified",
    finalPromptLangLabel: "The language for the final prompt itself MUST be: {TARGET_LANGUAGE}.",
    constructPromptInstruction: "Now, based on whether the type is MVP or AGENTIC, construct the prompt using the following templates and information.",
    
    // Enhanced MVP Section
    mvpTemplateHeader: "For an \"MVP\" type prompt, generate a complete executable prompt:",
    mvpGenerateInstruction: "Generate a complete, executable prompt using this exact structure:",
    mvpSystemRole: "You are an excellent {expertRolePlaceholder}: knowledgeable, precise, pedagogical. Your mission is to {missionPlaceholder}.",
    mvpExpertPlaceholder: "Expert",
    mvpMissionPlaceholder: "help effectively",
    
    // Enhanced Methodology for MVP
    mvpMethodologyHeader: "DETAILED METHODOLOGY - Follow this structured approach:",
    mvpAnalysisHeader: "1. IN-DEPTH ANALYSIS:",
    mvpAnalysisTasks: [
      "Meticulously analyze all elements provided in the request above",
      "Identify explicit and implicit objectives, quality criteria, and success metrics",
      "Note technical, creative, and logistical constraints to be respected", 
      "Evaluate context, underlying challenges, and optimization opportunities",
      "Determine the most appropriate resources, tools, and approaches"
    ],
    mvpPlanningHeader: "2. STRATEGIC PLANNING:",
    mvpPlanningTasks: [
      "Consider multiple methodological approaches to address the request optimally",
      "Rigorously evaluate advantages, disadvantages, and implications of each strategy",
      "Select the most appropriate approach and formulate clear justification for this choice",
      "Plan logical structure, progression, and optimal organization of the deliverable",
      "Anticipate execution challenges and prepare adaptation strategies if necessary"
    ],
    mvpExecutionHeader: "3. PROFESSIONAL EXECUTION:",
    mvpExecutionTasks: [
      "Produce a deliverable organized according to clear professional architecture",
      "Use premium formatting with appropriate sections, subsections, and structural elements",
      "Integrate concrete examples, evidence, data, and relevant references to support quality",
      "Scrupulously respect all constraints, specifications, and formulated requirements",
      "Systematically aim for professional-level quality that exceeds standard expectations",
      "Personalize content to maximize its specific relevance and added value"
    ],
    
    mvpExpectedOutputFormat: "Expected output format:",
    mvpLength: "Length:",
    mvpStyle: "Style: Clear and structured",
    mvpLanguage: "Language: {TARGET_LANGUAGE}",
    
    // Fixed Example Instruction  
    mvpExampleInstruction: "Show the exact beginning of the expected deliverable - first 3-5 lines of actual output, not process description. Examples: For podcast â†’ 'Voice 1: Welcome everyone to today's show...', for lesson plan â†’ 'LESSON: [Title] | OBJECTIVES: Students will be able to...', for analysis â†’ 'EXECUTIVE SUMMARY: This analysis reveals...'. The example must be a direct sample of the deliverable.",
    
    mvpFooter: "CRITICAL: Generate ONLY the complete prompt above with <System>, <User>, and <Example> sections. Do not add meta-commentary or explanations outside the prompt structure.",
    
    // Enhanced AGENTIC Section
    agenticTemplateHeader: "For an \"AGENTIC\" type prompt, generate a complete executable prompt with self-assessment capabilities:",
    agenticGenerateInstruction: "Generate a complete, executable AGENTIC prompt using this exact structure:",
    agenticTitleInstruction: "[Generate a concise and descriptive title (max 5-7 words) derived from the user's raw request.]",
    agenticRole: "{expertRolePlaceholder} (Agentic AI)",
    agenticExpertPlaceholder: "Expert Analyst", 
    agenticNote: "*Note: \"Agentic AI\" means an AI capable of acting autonomously, thinking, and iterating on its work.*",
    agenticContext: "Context:",
    agenticInstructionsHeader: "Instructions:",
    
    // Same detailed methodology for AGENTIC (reusing MVP tasks)
    agenticAnalysisHeader: "1. IN-DEPTH ANALYSIS:",
    agenticAnalysisTasks: [
      "Meticulously analyze all elements provided related to the Context above",
      "Identify explicit and implicit objectives, quality criteria, and success metrics",
      "Note technical, creative, and logistical constraints to be respected",
      "Evaluate context, underlying challenges, and optimization opportunities", 
      "Determine the most appropriate resources, tools, and approaches"
    ],
    agenticThinkingHeader: "2. STRATEGIC PLANNING:",
    agenticThinkingTasks: [
      "Consider multiple methodological approaches to address the Context optimally",
      "Rigorously evaluate advantages, disadvantages, and implications of each strategy",
      "Select the most appropriate approach and formulate clear justification for this choice",
      "Plan logical structure, progression, and optimal organization of the deliverable",
      "Anticipate execution challenges and prepare adaptation strategies if necessary"
    ],
    agenticDevelopmentHeader: "3. PROFESSIONAL EXECUTION:",
    agenticDevelopmentTasks: [
      "Produce a deliverable organized according to clear professional architecture",
      "Use premium formatting with appropriate sections, subsections, and structural elements", 
      "Integrate concrete examples, evidence, data, and relevant references to support quality",
      "Scrupulously respect all constraints, specifications, and formulated requirements",
      "Systematically aim for professional-level quality that exceeds standard expectations",
      "Personalize content to maximize its specific relevance and added value"
    ],
    
    // Self-Assessment (AGENTIC only)
    agenticSelfAssessmentHeader: "4. SELF-ASSESSMENT AND CONTINUOUS IMPROVEMENT:",
    agenticSelfAssessmentQuestion1: "At the end of its work, the AI executing this prompt **must always ask the user verbatim**:\n    \"ðŸ¤” Would you like me to evaluate this result against key criteria and provide suggestions for improvement? (Yes/No)\"",
    agenticSelfAssessmentInstruction: "If the user responds \"Yes\" (or similar affirmative), the AI should then perform a self-assessment using the following evaluation method, presenting it in a table:",
    agenticEvaluationCriteria: {
        education: ['Pedagogical Clarity', 'Level Appropriateness', 'Learner Engagement', 'Logical Progression'],
        technical: ['Technical Accuracy', 'Completeness of Analysis', 'Rigorous Methodology', 'Actionable Recommendations'],
        other: ['Originality', 'Coherence', 'Impact', 'Quality of Execution']
    },
    agenticEvalTableHeader: "| Criterion                     | Rating (/10) | Justification for Rating | Concrete Suggestions for Improvement |\n    |-------------------------------|--------------|--------------------------|--------------------------------------|",
    agenticSelfAssessmentQuestion2: "After presenting the evaluation, the AI **must also ask the user verbatim**:\n    \"Based on the evaluation above, would you like me to attempt to improve the draft? (Yes/No)\"",
    agenticFooter: "CRITICAL: Generate ONLY the complete prompt above with Title, <System>, <User>, and <Example> sections. Do not add meta-commentary or explanations outside the prompt structure.",
  },
  
  fr: {
    systemInstructionBase: "Vous Ãªtes un ingÃ©nieur de prompts expert. GÃ©nÃ©rez un prompt complet et exÃ©cutable suivant exactement le format : <System>, <User>, <Example>. Le prompt final doit Ãªtre en {TARGET_LANGUAGE} et prÃªt Ã  Ãªtre utilisÃ© immÃ©diatement par une IA. Incluez une mÃ©thodologie dÃ©taillÃ©e dans la section User et des exemples convaincants. Ne gÃ©nÃ©rez QUE le texte du prompt - aucun mÃ©ta-commentaire ou explication en dehors de la structure du prompt.",
    
    userQueryHeader: "Veuillez gÃ©nÃ©rer un prompt structurÃ©. Voici les dÃ©tails :",
    rawRequestLabel: "Objectif / Demande brute de l'utilisateur :",
    promptTypeLabel: "Type de structure de prompt choisi :",
    domainLabel: "Domaine :",
    outputLengthLabel: "Longueur de sortie souhaitÃ©e pour l'IA utilisant le prompt gÃ©nÃ©rÃ© :",
    expertRoleLabel: "RÃ´le d'expert pour l'IA utilisant le prompt gÃ©nÃ©rÃ© :",
    missionLabel: "Mission principale pour l'IA utilisant le prompt gÃ©nÃ©rÃ© :",
    constraintsLabel: "Contraintes pour l'IA utilisant le prompt gÃ©nÃ©rÃ© (une par ligne) :",
    noneSpecified: "Aucune spÃ©cifiÃ©e",
    finalPromptLangLabel: "La langue du prompt final lui-mÃªme DOIT Ãªtre : {TARGET_LANGUAGE}.",
    constructPromptInstruction: "Maintenant, selon que le type est MVP ou AGENTIQUE, gÃ©nÃ©rez le prompt en utilisant les modÃ¨les et informations suivants.",
    
    // Enhanced MVP Section - French
    mvpTemplateHeader: "Pour un prompt de type \"MVP\", gÃ©nÃ©rez un prompt exÃ©cutable complet :",
    mvpGenerateInstruction: "GÃ©nÃ©rez un prompt complet et exÃ©cutable en utilisant exactement cette structure :",
    mvpSystemRole: "Vous Ãªtes un excellent {expertRolePlaceholder} : compÃ©tent, prÃ©cis, pÃ©dagogue. Votre mission est d'{missionPlaceholder}.",
    mvpExpertPlaceholder: "Expert",
    mvpMissionPlaceholder: "aider efficacement",
    
    // Enhanced Methodology for MVP - French
    mvpMethodologyHeader: "MÃ‰THODOLOGIE DÃ‰TAILLÃ‰E - Suivez cette approche structurÃ©e :",
    mvpAnalysisHeader: "1. ANALYSE APPROFONDIE :",
    mvpAnalysisTasks: [
      "Analysez mÃ©ticuleusement tous les Ã©lÃ©ments fournis dans la demande ci-dessus",
      "Identifiez les objectifs explicites et implicites, critÃ¨res de qualitÃ© et mÃ©triques de rÃ©ussite",
      "Notez les contraintes techniques, crÃ©atives et logistiques Ã  respecter",
      "Ã‰valuez le contexte, les dÃ©fis sous-jacents et les opportunitÃ©s d'optimisation",
      "DÃ©terminez les ressources, outils et approches les plus appropriÃ©s"
    ],
    mvpPlanningHeader: "2. PLANIFICATION STRATÃ‰GIQUE :",
    mvpPlanningTasks: [
      "ConsidÃ©rez de multiples approches mÃ©thodologiques pour aborder la demande de maniÃ¨re optimale",
      "Ã‰valuez rigoureusement les avantages, inconvÃ©nients et implications de chaque stratÃ©gie",
      "SÃ©lectionnez l'approche la plus appropriÃ©e et formulez une justification claire de ce choix",
      "Planifiez la structure logique, la progression et l'organisation optimale du livrable",
      "Anticipez les dÃ©fis d'exÃ©cution et prÃ©parez des stratÃ©gies d'adaptation si nÃ©cessaire"
    ],
    mvpExecutionHeader: "3. EXÃ‰CUTION PROFESSIONNELLE :",
    mvpExecutionTasks: [
      "Produisez un livrable organisÃ© selon une architecture professionnelle claire",
      "Utilisez un formatage premium avec sections, sous-sections et Ã©lÃ©ments de structuration appropriÃ©s",
      "IntÃ©grez des exemples concrets, preuves, donnÃ©es et rÃ©fÃ©rences pertinentes pour Ã©tayer la qualitÃ©",
      "Respectez scrupuleusement toutes les contraintes, spÃ©cifications et exigences formulÃ©es",
      "Visez systÃ©matiquement un niveau de qualitÃ© professionnel qui dÃ©passe les attentes standard",
      "Personnalisez le contenu pour maximiser sa pertinence et sa valeur ajoutÃ©e spÃ©cifique"
    ],
    
    mvpExpectedOutputFormat: "Format de sortie attendu :",
    mvpLength: "Longueur :",
    mvpStyle: "Style : Clair et structurÃ©",
    mvpLanguage: "Langue : {TARGET_LANGUAGE}",
    
    // Fixed Example Instruction - French
    mvpExampleInstruction: "Montrez le dÃ©but exact du livrable attendu - les 3-5 premiÃ¨res lignes de sortie rÃ©elle, pas une description de processus. Exemples : Pour podcast â†’ 'Voix 1: Bienvenue dans cette Ã©mission...', pour plan de cours â†’ 'COURS: [Titre] | OBJECTIFS: Les apprenants seront capables de...', pour analyse â†’ 'SYNTHÃˆSE EXÃ‰CUTIVE: Cette analyse rÃ©vÃ¨le...'. L'exemple doit Ãªtre un Ã©chantillon direct du livrable.",
    
    mvpFooter: "CRITIQUE: GÃ©nÃ©rez UNIQUEMENT le prompt complet ci-dessus avec les sections <System>, <User>, et <Example>. N'ajoutez aucun mÃ©ta-commentaire ou explication en dehors de la structure du prompt.",
    
    // Enhanced AGENTIC Section - French (same structure, with self-assessment)
    agenticTemplateHeader: "Pour un prompt de type \"AGENTIQUE\", gÃ©nÃ©rez un prompt exÃ©cutable complet avec capacitÃ©s d'auto-Ã©valuation :",
    agenticGenerateInstruction: "GÃ©nÃ©rez un prompt AGENTIQUE complet et exÃ©cutable en utilisant exactement cette structure :",
    agenticTitleInstruction: "[GÃ©nÃ©rez un titre concis et descriptif (max 5-7 mots) dÃ©rivÃ© de la demande brute de l'utilisateur.]",
    agenticRole: "{expertRolePlaceholder} (IA Agentique)",
    agenticExpertPlaceholder: "Analyste Expert",
    agenticNote: "*Note : \"IA Agentique\" signifie une IA capable d'agir de maniÃ¨re autonome, de rÃ©flÃ©chir et d'itÃ©rer sur son travail.*",
    agenticContext: "Contexte :",
    agenticInstructionsHeader: "Instructions :",
    
    // Same detailed methodology for AGENTIC - French
    agenticAnalysisHeader: "1. ANALYSE APPROFONDIE DES INFORMATIONS FOURNIES :",
    agenticAnalysisTasks: [
      "Analysez mÃ©ticuleusement tous les Ã©lÃ©ments fournis relatifs au Contexte ci-dessus",
      "Identifiez les objectifs explicites et implicites, critÃ¨res de qualitÃ© et mÃ©triques de rÃ©ussite",
      "Notez les contraintes techniques, crÃ©atives et logistiques Ã  respecter",
      "Ã‰valuez le contexte, les dÃ©fis sous-jacents et les opportunitÃ©s d'optimisation",
      "DÃ©terminez les ressources, outils et approches les plus appropriÃ©s"
    ],
    agenticThinkingHeader: "2. RÃ‰FLEXION APPROFONDIE & PLANIFICATION :",
    agenticThinkingTasks: [
      "ConsidÃ©rez de multiples approches mÃ©thodologiques pour aborder le Contexte de maniÃ¨re optimale",
      "Ã‰valuez rigoureusement les avantages, inconvÃ©nients et implications de chaque stratÃ©gie",
      "SÃ©lectionnez l'approche la plus appropriÃ©e et formulez une justification claire de ce choix",
      "Planifiez la structure logique, la progression et l'organisation optimale du livrable",
      "Anticipez les dÃ©fis d'exÃ©cution et prÃ©parez des stratÃ©gies d'adaptation si nÃ©cessaire"
    ],
    agenticDevelopmentHeader: "3. DÃ‰VELOPPEMENT STRUCTURÃ‰ & EXÃ‰CUTION :",
    agenticDevelopmentTasks: [
      "Produisez un livrable organisÃ© selon une architecture professionnelle claire",
      "Utilisez un formatage premium avec sections, sous-sections et Ã©lÃ©ments de structuration appropriÃ©s",
      "IntÃ©grez des exemples concrets, preuves, donnÃ©es et rÃ©fÃ©rences pertinentes pour Ã©tayer la qualitÃ©",
      "Respectez scrupuleusement toutes les contraintes, spÃ©cifications et exigences formulÃ©es",
      "Visez systÃ©matiquement un niveau de qualitÃ© professionnel qui dÃ©passe les attentes standard",
      "Personnalisez le contenu pour maximiser sa pertinence et sa valeur ajoutÃ©e spÃ©cifique"
    ],
    
    // Self-Assessment (AGENTIC only) - French
    agenticSelfAssessmentHeader: "4. AUTO-Ã‰VALUATION ET AMÃ‰LIORATION CONTINUE :",
    agenticSelfAssessmentQuestion1: "Ã€ la fin de son travail, l'IA exÃ©cutant ce prompt **doit toujours demander Ã  l'utilisateur textuellement** :\n    \"ðŸ¤” Souhaitez-vous que j'Ã©value ce rÃ©sultat par rapport Ã  des critÃ¨res clÃ©s et que je fournisse des suggestions d'amÃ©lioration ? (Oui/Non)\"",
    agenticSelfAssessmentInstruction: "Si l'utilisateur rÃ©pond \"Oui\" (ou une affirmation similaire), l'IA doit alors effectuer une auto-Ã©valuation en utilisant la mÃ©thode d'Ã©valuation suivante, en la prÃ©sentant dans un tableau :",
    agenticEvaluationCriteria: {
        education: ['ClartÃ© PÃ©dagogique', 'AdÃ©quation au Niveau', 'Engagement de l\'Apprenant', 'Progression Logique'],
        technical: ['Exactitude Technique', 'ComplÃ©tude de l\'Analyse', 'MÃ©thodologie Rigoureuse', 'Recommandations Actionnables'],
        other: ['OriginalitÃ©', 'CohÃ©rence', 'Impact', 'QualitÃ© d\'ExÃ©cution']
    },
    agenticEvalTableHeader: "| CritÃ¨re                       | Note (/10)   | Justification de la Note | Suggestions ConcrÃ¨tes d'AmÃ©lioration |\n    |-------------------------------|--------------|--------------------------|--------------------------------------|",
    agenticSelfAssessmentQuestion2: "AprÃ¨s avoir prÃ©sentÃ© l'Ã©valuation, l'IA **doit Ã©galement demander Ã  l'utilisateur textuellement** :\n    \"Sur la base de l'Ã©valuation ci-dessus, souhaitez-vous que j'essaie d'amÃ©liorer le brouillon ? (Oui/Non)\"",
    agenticFooter: "CRITIQUE: GÃ©nÃ©rez UNIQUEMENT le prompt complet ci-dessus avec les sections Titre, <System>, <User>, et <Example>. N'ajoutez aucun mÃ©ta-commentaire ou explication en dehors de la structure du prompt.",
  }
};

const GEMINI_MODEL_NAME = 'gemini-2.5-pro-preview-05-06'; // As per user request

// Simple UUID generator (same as register.ts)
function generateUUID(): string {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c == 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

/**
 * Build prompt query based on parameters
 */
function buildPromptQuery(params: GeneratePromptParams, tMeta: any): { systemInstruction: string; userQuery: string } {
  const {
    rawRequest,
    promptType,
    domain,
    language,
    outputLength,
    expertRole,
    mission,
    constraints,
  } = params;

  const finalPromptTargetLanguageString = language === 'fr' ? 'FranÃ§ais' : 'English';
  const formattedConstraints = constraints ? 
    constraints.split('\n').filter(c => c.trim()).map(c => `- ${c.trim()}`).join('\n') : '';
  
  // Enhanced system instruction with language replacement
  const systemInstruction = tMeta.systemInstructionBase.replace('{TARGET_LANGUAGE}', finalPromptTargetLanguageString);
  
  let userQuery = `
${tMeta.userQueryHeader}

${tMeta.rawRequestLabel}
"${rawRequest}"

${tMeta.promptTypeLabel} ${promptType}
${tMeta.domainLabel} ${domain}
${tMeta.outputLengthLabel} ${outputLength}
${tMeta.expertRoleLabel} ${expertRole || (promptType === 'MVP' ? tMeta.mvpExpertPlaceholder : tMeta.agenticExpertPlaceholder)}
${tMeta.missionLabel} ${mission || tMeta.mvpMissionPlaceholder}
${tMeta.constraintsLabel}
${constraints ? formattedConstraints : tMeta.noneSpecified}
${tMeta.finalPromptLangLabel.replace('{TARGET_LANGUAGE}', finalPromptTargetLanguageString)}

${tMeta.constructPromptInstruction}
`;

  if (promptType === 'MVP') {
    userQuery += `
${tMeta.mvpTemplateHeader}

${tMeta.mvpGenerateInstruction}

<System>:
${tMeta.mvpSystemRole
    .replace('{expertRolePlaceholder}', expertRole || tMeta.mvpExpertPlaceholder)
    .replace('{missionPlaceholder}', mission || tMeta.mvpMissionPlaceholder)}

<User>:
${rawRequest}

${tMeta.mvpMethodologyHeader}

${tMeta.mvpAnalysisHeader}
${tMeta.mvpAnalysisTasks.map((task: string) => `â€¢ ${task}`).join('\n')}

${tMeta.mvpPlanningHeader}
${tMeta.mvpPlanningTasks.map((task: string) => `â€¢ ${task}`).join('\n')}

${tMeta.mvpExecutionHeader}
${tMeta.mvpExecutionTasks.map((task: string) => `â€¢ ${task}`).join('\n')}

Contraintes spÃ©cifiques :
${constraints ? formattedConstraints : tMeta.noneSpecified}

Format attendu : ${outputLength}, ${tMeta.mvpStyle.toLowerCase()}, ${tMeta.mvpLanguage.replace('{TARGET_LANGUAGE}', finalPromptTargetLanguageString)}

<Example>:
${tMeta.mvpExampleInstruction}

${tMeta.mvpFooter}
`;
  } else { // AGENTIC
    const criteriaDomain = (domain === 'education' || domain === 'technical') ? domain : 'other';
    const evaluationCriteriaList = tMeta.agenticEvaluationCriteria[criteriaDomain];
    
    const criteriaTableMarkdown = evaluationCriteriaList.map((c: string) => 
      `| ${c.padEnd(29)} |              |                          |                                      |`
    ).join('\n');

    userQuery += `
${tMeta.agenticTemplateHeader}

${tMeta.agenticGenerateInstruction}

Title: ${tMeta.agenticTitleInstruction}

<System>:
${tMeta.agenticRole.replace('{expertRolePlaceholder}', expertRole || tMeta.agenticExpertPlaceholder)} ${tMeta.agenticNote} ${language === 'fr' ? 'Votre mission est d\'' : 'Your mission is to '}${mission || tMeta.mvpMissionPlaceholder}.

<User>:
${rawRequest}

${tMeta.agenticInstructionsHeader}

${tMeta.agenticAnalysisHeader}
${tMeta.agenticAnalysisTasks.map((task: string) => `â€¢ ${task}`).join('\n')}

${tMeta.agenticThinkingHeader}
${tMeta.agenticThinkingTasks.map((task: string) => `â€¢ ${task}`).join('\n')}

${tMeta.agenticDevelopmentHeader}
${tMeta.agenticDevelopmentTasks.map((task: string) => `â€¢ ${task}`).join('\n')}

${tMeta.agenticSelfAssessmentHeader}
${tMeta.agenticSelfAssessmentQuestion1}

${tMeta.agenticSelfAssessmentInstruction}
${tMeta.agenticEvalTableHeader}
${criteriaTableMarkdown}

${tMeta.agenticSelfAssessmentQuestion2}

Contraintes spÃ©cifiques :
${constraints ? formattedConstraints : tMeta.noneSpecified}

Format attendu : ${outputLength}, ${tMeta.mvpStyle.toLowerCase()}, ${tMeta.mvpLanguage.replace('{TARGET_LANGUAGE}', finalPromptTargetLanguageString)}

<Example>:
${language === 'fr' ? '[Montrez le dÃ©but exact du livrable attendu avec le format du titre et les premiÃ¨res lignes de contenu rÃ©el]' : '[Show the exact beginning of the expected deliverable with the title format and first few lines of actual content]'}

${tMeta.agenticFooter}
`;
  }

  return { systemInstruction, userQuery };
}

export const onRequestPost = async (context: any) => {
  const { request, env } = context;
  
  try {
    console.log('=== GENERATE PROMPT ENDPOINT ===');
    
    // Basic environment check
    if (!env.JWT_SECRET) {
      return new Response(JSON.stringify({
        success: false,
        error: {
          code: 'CONFIG_ERROR',
          message: 'JWT configuration missing'
        }
      }), {
        status: 503,
        headers: { 'Content-Type': 'application/json' }
      });
    }
    
    if (!env.API_KEY) {
      return new Response(JSON.stringify({
        success: false,
        error: {
          code: 'CONFIG_ERROR',
          message: 'API key configuration missing'
        }
      }), {
        status: 503,
        headers: { 'Content-Type': 'application/json' }
      });
    }
    
    // Get token from Authorization header
    const authHeader = request.headers.get('Authorization');
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return new Response(JSON.stringify({
        success: false,
        error: {
          code: 'NO_TOKEN',
          message: 'Authorization token required'
        }
      }), {
        status: 401,
        headers: { 'Content-Type': 'application/json' }
      });
    }
    
    const token = authHeader.substring(7);
    
    // Verify JWT
    let user;
    try {
      user = await verifyJWT(token, env.JWT_SECRET);
    } catch (error) {
      return new Response(JSON.stringify({
        success: false,
        error: {
          code: 'INVALID_TOKEN',
          message: 'Invalid or expired token'
        }
      }), {
        status: 401,
        headers: { 'Content-Type': 'application/json' }
      });
    }
    
    // Parse JSON
    const params: GeneratePromptParams = await request.json();
    console.log('Generating prompt for user:', user.userId);
    
    // Get translations
    const tMeta = metaPromptTranslations[params.language] || metaPromptTranslations.en;
    
    // Build prompt query
    const { systemInstruction, userQuery } = buildPromptQuery(params, tMeta);

    // Initialize Gemini AI
    const ai = new GoogleGenAI({ apiKey: env.API_KEY });

    // Call Gemini API
    const result = await ai.models.generateContent({
      model: GEMINI_MODEL_NAME,
      contents: userQuery,
      config: {
        systemInstruction: systemInstruction,
      }
    });
     
    if (!result || typeof result.text !== 'string') {
      throw new Error('Invalid response from Gemini API');
    }

    console.log('Prompt generated successfully for user:', user.userId);

    return new Response(JSON.stringify({
      success: true,
      prompt: result.text
    }), {
      status: 200,
      headers: { 'Content-Type': 'application/json' }
    });

  } catch (error: any) {
    console.error('Generate prompt error:', error);
    
    // Handle specific error types
    let errorResponse = {
      code: 'INTERNAL_ERROR',
      message: 'Unable to generate prompt'
    };

    if (error?.message) {
      if (error.message.includes('API key not valid') || error.message.includes('API_KEY_INVALID')) {
        errorResponse = {
          code: 'API_KEY_ERROR',
          message: 'Service configuration error'
        };
      } else if (error.message.toLowerCase().includes('quota')) {
        errorResponse = {
          code: 'QUOTA_EXCEEDED',
          message: 'Service temporarily unavailable due to high demand'
        };
      }
    }
    
    return new Response(JSON.stringify({
      success: false,
      error: errorResponse
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
};
